{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I will be implementing a naive bayes baseline classifier. Additionally, I will be using pytorch to implement a binary logistic regression classifier. The task is sentiment classification for hotel reviews. The input to the model will be a text review, and the output label is a 1 or 0 marking it as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Sentiment Classification Dataset Exploration\n",
    "\n",
    "The training data for this task consists of a collection of short hotel reviews. The data is formatted as one review per line. Each line starts with a unique identifier for the review (as in ID-2001) followed by tab and the text of the review.  The reviews are not tokenized or sentence segmented in any way (the words are space separated). The positive reviews and negative reviews appear in separate files namely [hotelPosT-train.txt](data/hotelPosT-train.txt) and [hotelNegT-train.txt](data/hotelNegT-train.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "pos_datapath = \"data/hotelPosT-train.txt\"\n",
    "neg_datapath = \"data/hotelNegT-train.txt\"\n",
    "all_texts, all_labels = load_train_data(pos_datapath, neg_datapath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at what is in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Positive Example ---\n",
      "This hotel was fantastic, everything about it was simply amazing. Not only that, but on my first attempt to find the place, my GPS took me to the wrong location (another Hyatt Place) and even THAT location was clean, and had nice attendants who promptly directed me to the other location.  The price and amenities are simply unbeatable. Due to extending my stay, I had to switch hotels, and let me say, this hotel offered twice the value at half the cost. When you enter, the room is split into multiple rooms, the TV is huge and HD, the WiFi is free, and the beds are so comfortable. Downstairs, they have a 24/7 desert bar, you simply walk down, tell them what you want, and they add it to your tab (they don't even ask for your room number, they remember it!). So convenient and amazing. When you show up, they even offer you a personalized tour!  And when you wake up, stop by the breakfast. Their biscuits and gravy are to die for.\n",
      "\n",
      "--- Negative Example ---\n",
      "The Rio hotel is the absolute worst hotel I've stayed in on or just off the strip! It had the worst service! As we would stroll down the rundown hallways the smell of room service dishes and smoke was so dissapointing! The same left over food was left out for our two days stay. We could smell smoke in our rooms from the casino. My husband had trouble sleeping as the neon lights could be seen in our rooms with the curtains drawn. The casino was like an old bar room. Really bad ventilation! Last but not least! It took over sixty minutes to check out!\n"
     ]
    }
   ],
   "source": [
    "# print positive and negative examples from all_texts\n",
    "def random_sample(texts, labels, label):\n",
    "    data_by_label = {}\n",
    "    for lab, text in zip(labels, texts):\n",
    "        if lab not in data_by_label:\n",
    "            data_by_label[lab] = []\n",
    "        data_by_label[lab].append(text)\n",
    "    return random.choice(data_by_label[label])\n",
    "\n",
    "print(\"--- Positive Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=1))\n",
    "print(\"\\n--- Negative Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "\n",
    "This is the test dataset that I will use to report the results on. This set is the unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "\n",
    "test_datapath = \"./data/HW2-testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Print the number of \"positive\" and \"negative\" samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know the distribution of the training examples. More often than not, we will have to work with datasets that are not \"balanced\" with respect to the labels of the samples. For this task, let us print out the number of examples that have label = 1 and label = 0, respectively, in std:out or plot a pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 94)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_distribution(labels):\n",
    "    \"\"\"\n",
    "    TODO: Replace the line `raise NotImplementedError` with your code\n",
    "    to print the labels distribution.\n",
    "    \n",
    "    Args:\n",
    "        labels (List[int]): Labels for the dataset. 1 = postive, 0 = negative\n",
    "    \n",
    "    Returns\n",
    "        pos_count, neg_count (int, int): The counts of each label\n",
    "    \"\"\"\n",
    "    # raise NotImplementedError\n",
    "    pos_labels = [label for label in labels if label == 1]\n",
    "    neg_labels = [label for label in labels if label == 0]\n",
    "\n",
    "    return len(pos_labels), len(neg_labels)\n",
    "\n",
    "label_distribution(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Split Training and Development Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of coming with the best parameters for the model we will have to split the dataset into training and development sets. Make sure the splits follow the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(texts, labels):\n",
    "    \"\"\"\n",
    "    Split the dataset randomly into 80% training and 20% development set.\n",
    "    Ensure the splits have the same label distribution using stratification.\n",
    "    \"\"\"\n",
    "    train_texts, dev_texts, train_labels, dev_labels = train_test_split(\n",
    "        texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    return train_texts, train_labels, dev_texts, dev_labels\n",
    "\n",
    "# Example usage\n",
    "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_train_labels 151\n",
      "len_test_labels 38\n"
     ]
    }
   ],
   "source": [
    "print(\"len_train_labels\", len(train_labels))\n",
    "print(\"len_test_labels\", len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution:\n",
      "Train Label Distribution: (76, 75)\n",
      "Dev Label Distribution:\n",
      "Dev Label Distribution: (19, 19)\n"
     ]
    }
   ],
   "source": [
    "print('Train Label Distribution:')\n",
    "print('Train Label Distribution:', label_distribution(train_labels))\n",
    "\n",
    "print('Dev Label Distribution:')\n",
    "print('Dev Label Distribution:', label_distribution(dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Evaluation Metrics\n",
    "\n",
    "Implement the evaulation metrics: Accuracy, Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Accuracy is correct predictions / all predicitons\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(p == t for p, t in zip(predicted_labels, true_labels))\n",
    "    total_predictions = len(true_labels)\n",
    "    return correct_predictions / total_predictions #if total_predictions > 0 else 0\n",
    "    # raise NotImplementedError\n",
    "\n",
    "def precision(predicted_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    Args:\n",
    "    predicted_labels (list or array): List or array of predicted labels (1 for positive, 0 for negative).\n",
    "    true_labels (list or array): List or array of true labels (1 for positive, 0 for negative).\n",
    "    \n",
    "    Returns:\n",
    "    float: Precision score.\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    \n",
    "    for pred, true in zip(predicted_labels, true_labels):\n",
    "        if pred == 1 and true == 1:\n",
    "            true_positives += 1\n",
    "        elif pred == 1 and true == 0:\n",
    "            false_positives += 1\n",
    "    \n",
    "    # if true_positives + false_positives == 0:\n",
    "    #     return 0.0  # Avoid division by zero\n",
    "    \n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "    # raise NotImplementedError\n",
    "\n",
    "def recall(predicted_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for pred, true in zip(predicted_labels, true_labels):\n",
    "        if pred == 1 and true == 1:\n",
    "            true_positives += 1\n",
    "        elif pred == 0 and true == 1:\n",
    "            false_negatives += 1\n",
    "    \n",
    "    # if true_positives + false_positives == 0:\n",
    "    #     return 0.0  # Avoid division by zero\n",
    "    \n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "    # raise NotImplementedError\n",
    "\n",
    "def f1_score(predicted_labels, true_labels):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    precision_val = precision(predicted_labels, true_labels)\n",
    "    recall_val = recall(predicted_labels, true_labels)\n",
    "\n",
    "    return 2 * (precision_val * recall_val) / (precision_val + recall_val)\n",
    "    # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "em_test_labels = [0]*6 + [1]*4\n",
    "em_test_predictions = [0]*8 + [1]*2\n",
    "\n",
    "em_test_accuracy = 0.8\n",
    "em_test_precision = 1.0\n",
    "em_test_recall = 0.5\n",
    "em_test_f1 = 2/3\n",
    "\n",
    "assert accuracy(em_test_predictions, em_test_labels) == em_test_accuracy\n",
    "assert precision(em_test_predictions, em_test_labels) == em_test_precision \n",
    "assert recall(em_test_predictions, em_test_labels) == em_test_recall\n",
    "assert f1_score(em_test_predictions, em_test_labels) == em_test_f1\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to come up with baselines for the classifications to compare the more complicated models with. The baselines are also useful as a debugging method for our actual classfication model. I will create two baselines:\n",
    "\n",
    "1. Random Chance\n",
    "2. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Random Chance Classifier\n",
    "\n",
    "A random chance classifier predicts the label according to the label's distribution. As an example, if the label 1 appears 70% of the times in the training set, you predict 70 out of 100 times the label 1 and label 0 30% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(train_labels, num_samples):\n",
    "    \"\"\"\n",
    "    Using the label distribution, predict the label num_sample number of times\n",
    "\n",
    "    Predicts the label num_samples times based on the distribution of labels in train_labels.\n",
    "    \n",
    "    Args:\n",
    "    train_labels (list or array): List or array of true labels.\n",
    "    num_samples (int): The number of predictions to generate.\n",
    "    \n",
    "    Returns:\n",
    "    np.array: Predicted labels based on the distribution.\n",
    "    \"\"\"\n",
    "    # Calculate the distribution of labels\n",
    "    unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "    probabilities = counts / len(train_labels)  # Get the probability of each label\n",
    "    # print(\"probabilities: \", probabilities)\n",
    "    # Predict labels according to the calculated probabilities\n",
    "    predictions = np.random.choice(unique_labels, size=num_samples, p=probabilities)\n",
    "    \n",
    "    return predictions\n",
    "    # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "rc_labels = np.array([1]*10 + [0]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 3)\n",
    "assert len(rc_predictions) == 3\n",
    "assert len(set(rc_predictions).difference({0, 1})) == 0\n",
    "\n",
    "rc_labels = np.array([0]*10 + [1]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 100)\n",
    "p, n = label_distribution(rc_predictions)\n",
    "assert n > p\n",
    "\n",
    "rc_labels = np.array([1]*10 + [0]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 100)\n",
    "p, n = label_distribution(rc_predictions)\n",
    "assert p > n\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Naive Bayes Classifier\n",
    "\n",
    "In this task, I will implement a Naive Bayes Classifier using the tokens in the training sample. As a preprocessing step, I will tokenize via whitespace separation and lowercase all tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.2: Preprocessing\n",
    "\n",
    "Tokenize text by separating by whitespace, and then lowercase all tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Takes a string of text and returns a list of the whitespace-separated and lowercased tokens.\n",
    "    \"\"\"\n",
    "    tokens = text.lower().split()\n",
    "    # You might wanna remove stop words.\n",
    "    return tokens\n",
    "    # raise NotImplementedError\n",
    "    \n",
    "test_string = \"This sentence needs to be preprocessed.\"\n",
    "\n",
    "assert preprocess(test_string) == ['this', 'sentence', 'needs', 'to', 'be', 'preprocessed.']\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.3: The Naive Bayes Class\n",
    "\n",
    "The standard way of implementing classifiers like Naive Bayes is to implement the two methods: \"fit\" and \"predict\". The fit method expects the training data along with labels, and the predict method predicts the labels for the provides texts of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.label_word_counter = defaultdict(Counter)\n",
    "        self.label_words_count = defaultdict(int)\n",
    "        self.label_count = defaultdict(int)\n",
    "        self.vocabulary = set()\n",
    "\n",
    "    # def preprocess(self, text):\n",
    "    #     # Simple text preprocessing: lowercasing and removing non-alphanumeric characters\n",
    "    #     return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "    def fit(self, texts, labels):\n",
    "        \"\"\"\n",
    "        1. Group samples by their labels\n",
    "        2. Preprocess each text\n",
    "        3. Count the words of the text for each label\n",
    "        \"\"\"\n",
    "        for text, label in zip(texts, labels):\n",
    "            words = preprocess(text)\n",
    "            self.vocabulary.update(words)\n",
    "            self.label_count[label] += 1\n",
    "            self.label_words_count[label] += len(words)\n",
    "            self.label_word_counter[label].update(words)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        \"\"\"\n",
    "        1. Preprocess the texts\n",
    "        2. Predict the class by using the likelihood with Bayes Method and Laplace Smoothing\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        total_docs = sum(self.label_count.values())\n",
    "\n",
    "        for text in texts:\n",
    "            words = preprocess(text)\n",
    "            label_probs = {}\n",
    "\n",
    "            for label in range(self.num_classes):\n",
    "                # Log prior probability\n",
    "                log_prob = np.log(self.label_count[label] / total_docs)\n",
    "\n",
    "                # Log likelihood with Laplace smoothing\n",
    "                for word in words:\n",
    "                    word_count = self.label_word_counter[label][word] + 1  # Laplace smoothing\n",
    "                    word_prob = word_count / (self.label_words_count[label] + vocab_size)\n",
    "                    log_prob += np.log(word_prob)\n",
    "\n",
    "                label_probs[label] = log_prob\n",
    "\n",
    "            # Choose the label with the highest probability\n",
    "            predictions.append(max(label_probs, key=label_probs.get))\n",
    "\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Baseline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is not hyperparameter-tuing required for the baselines, we can use the entirety of the training set (no need to split the dataset into train and development)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.5\n",
      "Naive Bayes F1: 0.8717948717948718\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "### DEV SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, dev_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(train_texts, train_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(dev_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.3673469387755102\n",
      "Naive Bayes F1: 0.8627450980392156\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "### TEST SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, test_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(all_texts, all_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(test_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Logistic Regression on Features\n",
    "\n",
    "Now let's try building a logistic regression based classifier on hand-engineered features.\n",
    "\n",
    "The following tasks are going to be the implementation of the components required in building a Logistic Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0: Feature Extraction\n",
    "\n",
    "This is perhaps the most challenging part of this project. \n",
    "\n",
    "This task requires a thorough understanding of the dataset to answer the important question, \"What is in the data?\". For this, we need to go through some of the datapoints and convert the signals that we think might help in identifying \"sentiment\" as features.\n",
    "\n",
    "Please use the files with postive and negative words attached in the assignment: [positive_words.txt](data/poisitive-words.txt) and  [negative_words.txt](data/negative-words.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_feature(text):\n",
    "    return \"happy\" in text\n",
    "# Read the text file and store each word in a list\n",
    "def read_words_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        words = [line.strip() for line in file.readlines()]\n",
    "    return words\n",
    "def count_positive_negative_words(text):\n",
    "\n",
    "    positive_words = read_words_from_file(\"./data/positive-words.txt\")\n",
    "    negative_words = read_words_from_file(\"./data/negative-words.txt\")\n",
    "    # print()\n",
    "    positive_count = sum(1 for word in text if word in positive_words)\n",
    "    negative_count = sum(1 for word in text if word in negative_words)\n",
    "\n",
    "    # positive_count = sum(1 for word in text.lower().split() if word in positive_words)\n",
    "    # negative_count = sum(1 for word in text.lower().split() if word in negative_words)\n",
    "    return positive_count, negative_count\n",
    "# Feature: Length of the review (number of words)\n",
    "def review_length(text):\n",
    "    # print(\"text: \", text)\n",
    "    # print(\"text type: \", type(text))\n",
    "    return len(text)\n",
    "\n",
    "# Feature: Count of exclamation marks (could indicate strong emotion)\n",
    "def count_exclamations(text):\n",
    "    return sum(part.count(\"!\") for part in text)\n",
    "\n",
    "def extract_features(text):\n",
    "    features = []\n",
    "    # TODO: Replace this with your own feature extraction functions.\n",
    "    \n",
    "    # Add individual features to the feature list\n",
    "    features.append(make_test_feature(text))\n",
    "    # print(\"text: \", text)\n",
    "    features.append(review_length(text))\n",
    "    features.append(count_exclamations(text))\n",
    "    # features.append(sentiment_polarity(text))\n",
    "    # features.append(has_negation(text))\n",
    "    \n",
    "    # Positive/Negative word count\n",
    "    pos_count, neg_count = count_positive_negative_words(text)\n",
    "    features.append(pos_count)\n",
    "    features.append(neg_count)\n",
    "    # TODO: add more features to the feature vector\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife, two-year old son and I stayed at La Quinta Inn in Garland, Texas during our vacation this Spring Break. The staff was very nice and accomodating. They quickly brought up a crib for our son soon after we requested one. The room was clean and very spacious. Our bed was also comfortable. A great breakfast came free with the stay. They offered scrambled eggs, waffles, cereals, pastries, and much more. We had a great stay here. It only cost us about $80 a night.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT CHANGE THE SIGNATURE OF THE function THOUGH ###\n",
    "\n",
    "def featurize_data(texts, labels):\n",
    "    features = [\n",
    "        extract_features(preprocess(text)) for text in texts\n",
    "    ]\n",
    "    return torch.FloatTensor(features), torch.FloatTensor(labels)\n",
    "\n",
    "# train_features, train_labels_tensor = featurize_data(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAAAnCAYAAADtl7EyAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAlqADAAQAAAABAAAAJwAAAAA67GmEAAAE9klEQVR4Ae2cgU3sMAyGw9MbADECYgLECIgJECMgJkA3wokJECMgJkCMgJgAMQJig758eXHl5oquvZ7bXJtKqG3iOPYf107iC84t+Pr+/q5ub2+r4+PjysNQXV5eVpQJJM/Pz6H89PQ00Ok6obG45yqXha6z5vn4+BgM6PPzszYqFOb9/v6+UTYmELnKNSYGc+greCVRBK8RB1aKprrnKtdUeBxWv9EzhVCYkVG5XOU6rNGdUNo4fwqhLxNPFdDIVa4Jh+rwur6+vg5zrdwkt5CLhYnl/PFPbiBOJQ+e4eTkJHSfm8eykMuvgN3Dw8ORFd57Yczq6erqyn19fe2Fn5Wyv/HFqNbrdQD6/Py8+vn56aXL+/t7tVqtfmPfKGdAPW0nnIbK1ej4EF9wqX5gJluWD8GMwdMhQfauXl9fJ9Wnj1zRAIMeyI3HJXzywfPMH/t1ghNjFcOra2sLbbr1Im1HvfOVI+Cone6pM21UwpINUTZL5X2Kex+54seAmBXekweMR+sQN4GdhHl0ZMza2tK30MFrkmvqTcRdlQZU+WpTHhHUepDSesv3XeXCoLQhoZsYDTwxJJGbMcMZyHtbWzFQoRn9jgAIPnrHO3ZIqIgDEFI5KYDUR9DDYOgQsmOXnZoNlQsPpacj4pHoPA2FqUdK24p36yR4FyIMJMfcWRfZl07DxyIfSeqh8F4y9wInMToJd7otdNDj1XjeK64SCtIJ3KGGvb2CkykzHQYxCD1HYzzxSmIo1PEu46vbYpQYlhidhbqNlQQdWnZmoUDhmSEC0eKzy51lCFURqQ8CeChPH1xq8VR9kCu0WxEg1mJcWwkLQUEgQeBv8l6/4rEkTYHHuru765SGqBm0PLDi9HxbajaL/MrFNJe12WMpMUcAo5JVBXs6enPNvPN+HYhHLff/kSUnHJojqY2KmlxyZ00py1vuCGyENzxV+nMKPBah6e3tbYO+j4IlFPZBaya0eKo4Wd/QKK4K653dDYJSUBBIEWA3Nu68ZpU7S+Us7wWBgkBBYD4IEMqXnEBfuv7mlizzQUmwSodLSaAvXX8Zb6v70hPoS9ffxq6WnkBfuv42VuW5Mt/wt8Um0Jeuv5lhwXjpCXQL/cnCSKpv2+DN8sAqX6zFIc9tYOZSb6W/3+/s/MOAQSmaXIDUcgCq/9ntzodPNS+rZ36bLr8c2dYHg9n1gCu8ctF/VoalQQVkXPfNzY3z2QXnT2o3dIX26emJgXAMnj/FTS6U83jhTvuPjw/naep2hAFyppRzSR39wIdy4UV9H4OAfuhlqT+/kfcfhHt5eTlqww7dPT7u7OysxmuoPtm0b4v/JND9YDOZb1zxVxuU1TlQwNO0+hgU5XIKBjr+aAzIwot5DftIpMmkDJqxLiv9495YfbpH6VZjQt9CN5a+5v0wuLsk0DEUbUjwENDgiVEiPHTayKCTEy9aOejTjVldb/VsrT9yo1f2h1z3BfDQBLr2PMiEYTBIPPP1kSKSZ224mo56ubTxSZnlfSz90SH1SCl2Y+tuietg3jq8aQ8FY/FKGBheTMIM3ksMS0Ie9fyJ96N8Cs/VF5Cu+sNXdJZwp9uiL3ihM8/Qz3K7AcW6XhcXF2Gy6Q0GY6qbeeDCZNwD6vwC4Ih/bQSoTPJ9SGDiXi8IaOsNM5RDA+2hTGK76A8oYIPO4CKXtPX3UMTiRxZJ/wB1ehRLQkYoygAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0.2: Feature Scaling\n",
    "\n",
    "In this task we will use the data normalization technique to ensure the scales of the feature are consistent.\n",
    "After featurizing the dataset, we need to call the following function before passing it to the classifier\n",
    "\n",
    "#### Normalization Formula\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    return the features transformed by the above formula of normalization\n",
    "    \"\"\"\n",
    "        # Compute the minimum and maximum values along the feature dimension (dim=0)\n",
    "    x_min = features.min(dim=0, keepdim=True).values\n",
    "    x_max = features.max(dim=0, keepdim=True).values\n",
    "    \n",
    "    # Normalize the features\n",
    "    normalized_features = (features - x_min) / (x_max - x_min + 1e-8)  # Adding epsilon to avoid division by zero\n",
    "    \n",
    "    return normalized_features\n",
    "    # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will implement the components needed to train the binary classifier using logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we define our pytorch logistic regression classifier (DO NOT EDIT THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        # We force output to be one, since we are doing binary logistic regression\n",
    "        self.output_size = 1\n",
    "        self.coefficients = torch.nn.Linear(input_dim, self.output_size)\n",
    "        # Initialize weights. Note that this is not strictly necessary,\n",
    "        # but you should test different initializations per lecture\n",
    "        initialize_weights(self.coefficients)\n",
    "        \n",
    "    def forward(self, features: torch.Tensor):\n",
    "        # We predict a number by multipling by the coefficients\n",
    "        # and then take the sigmoid to turn the score as logits\n",
    "        return torch.sigmoid(self.coefficients(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Initialize the weights.\n",
    "\n",
    "Initialization of the parameters is an important step to ensure the SGD algorithm converges to a global optimum. Typically, we need to try different initialization methods and compare the accuracy we achieve for the development set. In this task, implement the function that initializes the parameters to ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def initialize_weights(coefficients):\n",
    "    \"\"\"\n",
    "    TODO: Replace the line `raise NotImplementedError` with your code.\n",
    "    Initialize the weights of the coefficients by assigning the parameter\n",
    "    coefficients.weights.data = ...\n",
    "    \"\"\"\n",
    "    # Set all weights to 1.0\n",
    "    coefficients.weight.data.fill_(1.0)\n",
    "    \n",
    "    # Optionally, set bias to 0.0 if needed\n",
    "    if coefficients.bias is not None:\n",
    "        coefficients.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "test_module = torch.nn.Linear(5, 1)\n",
    "initialize_weights(test_module)\n",
    "assert test_module.weight.ravel().tolist() == [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the loss function by implementing binary cross-entropy loss between the prediction and label. As a reminder, binary cross-entropy loss between the prediction y_hat and the target y, averaged over N examples, is:\n",
    "\n",
    "![loss.png](attachment:loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Logistic Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(prediction: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    TODO: Implement the logistic loss function between a prediction and label.\n",
    "    \"\"\"\n",
    "    # To prevent log(0) issues, we clamp predictions between a small epsilon and 1-epsilon\n",
    "    eps = 1e-7\n",
    "    prediction = torch.clamp(prediction, eps, 1 - eps)\n",
    "    # print(\"prediction: \", prediction)\n",
    "    # print(\"torch.log(1 - prediction):\", torch.log(1 - prediction))\n",
    "    # print(\"torch.log(prediction):\", torch.log(prediction))\n",
    "    loss = - (label * torch.log(prediction) + (1 - label) * torch.log(1 - prediction))\n",
    "    \n",
    "    # Return the mean loss over all samples\n",
    "    return loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Create an SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, learning_rate) -> torch.optim:\n",
    "    \"\"\"\n",
    "    Returns an Stocastic Gradient Descent Optimizer\n",
    "    See here for algorithms you can import: https://pytorch.org/docs/stable/optim.html\n",
    "    \"\"\"\n",
    "    return torch.optim.Adam(model.parameters(), learning_rate)\n",
    "    # return torch.optim.SGD(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5: Converting Logits into Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    with torch.no_grad():\n",
    "        \"\"\"\n",
    "        TODO: Replace the line `raise NotImplementedError`\n",
    "        with the logic of converting the logits into prediction labels (0, 1)\n",
    "        \"\"\"\n",
    "        logits = model(features)\n",
    "        logits = torch.squeeze(logits)\n",
    "        predictions = (logits >= 0.5).float()\n",
    "        return predictions\n",
    "        # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function (DO NOT EDIT THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/rlbty0wj62qgtp38sml170rr0000gn/T/ipykernel_4308/3686070062.py:3: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model\n",
    "):\n",
    "    samples = list(zip(train_features, train_labels))\n",
    "    random.shuffle(samples)\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    print(\"Training...\")\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features, labels = zip(*batch)\n",
    "            features = torch.stack(features)\n",
    "            labels = torch.stack(labels)\n",
    "            optimizer.zero_grad()\n",
    "            # Run the model\n",
    "            logits = model(features)\n",
    "            # Compute loss\n",
    "            loss = logistic_loss(torch.squeeze(logits), labels)\n",
    "            # In this logistic regression example,\n",
    "            # this entails computing a single gradient\n",
    "            loss.backward()\n",
    "            # Backpropogate the loss through our model\n",
    "            # Update our coefficients in the direction of the gradient.\n",
    "            optimizer.step()\n",
    "             # For logging\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        # Estimate the f1 score for the development set\n",
    "        dev_f1 = f1_score(predict(model, dev_features), dev_labels)\n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6: Train the classifier\n",
    "\n",
    "Run the following cell to train a logistic regressor on your hand-engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 767.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.7785831570625306\n",
      "Dev F1 0.6785714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2550.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.7531282365322113\n",
      "Dev F1 0.6545454545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5923.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 0.7321554958820343\n",
      "Dev F1 0.6415094339622641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 4585.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 0.7148058414459229\n",
      "Dev F1 0.6415094339622641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2590.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 0.700419956445694\n",
      "Dev F1 0.6538461538461537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 4115.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 0.6882759511470795\n",
      "Dev F1 0.6122448979591837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3024.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 0.677722442150116\n",
      "Dev F1 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5235.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 0.6682543873786926\n",
      "Dev F1 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5810.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 0.6595227420330048\n",
      "Dev F1 0.6521739130434783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2346.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 0.6513064742088318\n",
      "Dev F1 0.6818181818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5649.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 0.643473893404007\n",
      "Dev F1 0.6976744186046512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2405.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 0.6359490275382995\n",
      "Dev F1 0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5754.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 0.6286877930164337\n",
      "Dev F1 0.761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 4478.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss: 0.6216635704040527\n",
      "Dev F1 0.761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3533.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss: 0.6148590981960297\n",
      "Dev F1 0.761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5227.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 0.6082619547843933\n",
      "Dev F1 0.7804878048780488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5259.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss: 0.6018625557422638\n",
      "Dev F1 0.7804878048780488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1732.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 0.5956528902053833\n",
      "Dev F1 0.7804878048780488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5491.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 0.5896260201931\n",
      "Dev F1 0.7804878048780488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3370.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 0.5837756276130677\n",
      "Dev F1 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5274.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 0.5780958712100983\n",
      "Dev F1 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5942.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 0.572581273317337\n",
      "Dev F1 0.8205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3774.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 0.5672265589237213\n",
      "Dev F1 0.8205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5426.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 0.5620267182588577\n",
      "Dev F1 0.8421052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 4745.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 0.5569768726825715\n",
      "Dev F1 0.8648648648648649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2513.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 0.552072262763977\n",
      "Dev F1 0.8648648648648649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5643.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, loss: 0.5473083138465882\n",
      "Dev F1 0.918918918918919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3032.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 0.5426805883646011\n",
      "Dev F1 0.918918918918919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5459.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 0.5381846964359284\n",
      "Dev F1 0.8947368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 6090.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 0.5338164657354355\n",
      "Dev F1 0.8947368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "train_features, train_labels_tensor = featurize_data(train_texts, train_labels)\n",
    "train_features = normalize(train_features)\n",
    "dev_features, dev_labels_tensor = featurize_data(dev_texts, dev_labels)\n",
    "dev_features = normalize(dev_features)\n",
    "model = SentimentClassifier(train_features.shape[1]) \n",
    "optimizer = make_optimizer(model, learning_rate=0.01)\n",
    "\n",
    "trained_model = training_loop(\n",
    "    num_epochs,\n",
    "    16,\n",
    "    train_features,\n",
    "    train_labels_tensor,\n",
    "    dev_features,\n",
    "    dev_labels_tensor,\n",
    "    optimizer,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7: Get the predictions on the Test Set using the Trained model and print the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.4878048780487805\n",
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "### DEV SET RESULTS\n",
    "\n",
    "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)\n",
    "\n",
    "devset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
    "dev_random_f1 = f1_score(devset_prediction_random, dev_labels)\n",
    "print('Random Chance F1:', dev_random_f1)\n",
    "\n",
    "assert dev_random_f1 > 0\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: tensor(0.8947)\n",
      "F1-score 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "### DEV SET RESULTS - LOGISTIC REGRESSION\n",
    "\n",
    "dev_features, dev_labels = featurize_data(dev_texts, dev_labels)\n",
    "dev_features = normalize(dev_features)\n",
    "dev_logistic_accuracy = accuracy(predict(trained_model, dev_features), dev_labels.tolist())\n",
    "dev_logistic_f1 = f1_score(predict(trained_model, dev_features), dev_labels.tolist())\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', dev_logistic_accuracy)\n",
    "print('F1-score', dev_logistic_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.6274509803921569\n",
      "Naive Bayes F1: 0.8627450980392156\n"
     ]
    }
   ],
   "source": [
    "### TEST SET RESULTS - RANDOM CHANCE\n",
    "### DO NOT EDIT ###\n",
    "\n",
    "# load the test data\n",
    "test_datapath = \"data/HW2-testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)\n",
    "\n",
    "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
    "test_random_f1 = f1_score(testset_prediction_random, test_labels)\n",
    "print('Random Chance F1:', test_random_f1)\n",
    "testset_prediction_naive = naive_bayes_classifier.predict(test_texts)\n",
    "test_naive_f1 = f1_score(testset_prediction_naive, test_labels)\n",
    "print('Naive Bayes F1:', test_naive_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: tensor(0.8000)\n",
      "F1-score 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "### TEST SET RESULTS\n",
    "\n",
    "# load the test data\n",
    "test_datapath = \"data/HW2-testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)\n",
    "\n",
    "test_features, test_labels = featurize_data(test_texts, test_labels)\n",
    "test_features = normalize(test_features)\n",
    "test_logistic_accuracy = accuracy(predict(trained_model, test_features), test_labels.tolist())\n",
    "test_logistic_f1 = f1_score(predict(trained_model, test_features), test_labels.tolist())\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', test_logistic_accuracy)\n",
    "print('F1-score', test_logistic_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Azure_end_to_end_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
